Depends on: [[6. Visual Studio Code]], [CodeSinaia-2025](https://github.com/inproted/CodeSinaia-2025)
Resources: [Ollama](https://ollama.com/download)

- [x] Download [Ollama](https://ollama.com/download). Verify installation is successful from a command window, typing the following:
    ```
    > ollama
    Usage:
      ollama [flags]
      ollama [command]
      [...]
    ```
- [x] Download a [model](https://github.com/ollama/ollama). Scroll down to the **Model Library** section to select an AI model that fits your computer's spec. If unsure, go with the smallest you see, i.e. "**Gemma 3**" has 1 billion parameters and requires 815Mb of disk storage on your system. From a command window, run the following:
    ```
    > ollama pull gemma3:1b
    ```
   The model is downloaded in your user's profile:

| Windows   | C:\Users\YourName\\\.ollama\models |
| --------- | ---------------------------------- |
| Linux/Mac | ~/.ollama/models                   |

   To manage the models (since they consume significant storage on your computer) you can use the following commands:

     > ollama list
    NAME         ID              SIZE      MODIFIED
    gemma3:1b    8648f39daa8f    815 MB    24 minutes ago

    > ollama rm gemma3:1b
    deleted 'gemma3:1b'

   If you have to ^C a model while downloading, is likely files are left orphaned - nothing bad other than wasting space on your disk. To clean out the model fully go to file explorer and delete the content of the models folder

- [x] Verify everything works end-to-end. Still in command window run the following command (by using the name of the model you downloaded):

    ```
    > ollama run gemma3:1b
    >>> Hi there!
    Hi there to you too! How's your day going so far? ðŸ˜Š

    Is there anything youâ€™d like to chat about or need help with?

    >>> /bye
    > 
    ```
---
Interact with the model programmatically
- [ ] In a command window, install the __ollama__ python module:
```
	C:\Users\Florin>pip install ollama
	Defaulting to user installation because normal site-packages is not writeable
	Collecting ollama
	...
	Installing collected packages: ollama
	Successfully installed ollama-0.5.1
	
	C:\Users\Florin>
```
- [ ] In **VSCode**, opened on your local **CodeSinaia-2025** repository open the file "_HelloOllama.py_" and run it. If all went well, it should display an output like below:
```
	PS C:\Users\Florin\git\CodeSinaia-2025> & C:/Users/Florin/git/CodeSinaia-2025/.venv/Scripts/python.exe c:/Users/Florin/git/CodeSinaia-2025/HelloOllama.py
	<class 'ollama._types.GenerateResponse'>
	The capital of France is **Paris**. 
	
	Itâ€™s a common misconception that itâ€™s Lyon, but Paris is the official and recognized capital city. ðŸ˜Š
	PS C:\Users\Florin\git\CodeSinaia-2025> 
```
